{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ff970e",
   "metadata": {},
   "source": [
    "#### Primero importamos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3548785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para convertirlo en un df\n",
    "import pandas as pd\n",
    "# Para cálculos numericos\n",
    "import numpy as np\n",
    "# Para graficar\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Para normalizar los datos\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb16efe",
   "metadata": {},
   "source": [
    "## ***1.- Recopilación de Datos***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797233c6",
   "metadata": {},
   "source": [
    "he recogido este dataset aqui: https://www.kaggle.com/datasets/uciml/iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf656ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../3.- Datasets/iris.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da90af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# por si acaso creamos una copia del df\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b5af0e",
   "metadata": {},
   "source": [
    "## **2.- Exploración y Análisis de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5eab95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d92a75d",
   "metadata": {},
   "source": [
    "##### Según donde saque este dataset, survived representa con un 1 si sobrevivieron y 0 si no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f9bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vemos algunas metricas como la mediana, minimo, maximo etc..\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43022b41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22694007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c93ca28",
   "metadata": {},
   "source": [
    "#### Vamos a visualizar un poco nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a70d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Sex', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182fe70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='Embarked', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef988c",
   "metadata": {},
   "source": [
    "#### Nos conviene estratificar tambien la columna embarked, ya que esta un poco desigual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d4000",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Ticket', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b53ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='Cabin', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eda55e",
   "metadata": {},
   "source": [
    "#### Como vemos hay un monton de caracteristicas en el ticket y en cabin, nos convendria eliminarlos para hacer nuesto modelo mas sencillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5cb5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos ticket\n",
    "columna_a_eliminar = 'Ticket'\n",
    "df = df.drop(columna_a_eliminar, axis=1)\n",
    "\n",
    "# Eliminamos Cabin\n",
    "columna_a_eliminar = 'Cabin'\n",
    "df = df.drop(columna_a_eliminar, axis=1)\n",
    "\n",
    "# de paso eliminamos la columna name tambien ya que no parece muy relevante\n",
    "columna_a_eliminar = 'Name'\n",
    "df = df.drop(columna_a_eliminar, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8cbe57",
   "metadata": {},
   "source": [
    "## 3.- División de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e872e120",
   "metadata": {},
   "source": [
    "#### Hay que dividir los datos en entrenamiento, evaluación y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616237e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos train_test_split para dividir los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, val_set = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'la longitud de train_set es de: {len(train_set)}')\n",
    "print(f'la longitud de val_set es de: {len(val_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b297b2ed",
   "metadata": {},
   "source": [
    "#### Ahora separamos las etiquetas (salidas 'y'), de las caracteristicas (entradas 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos el de entrenamiento \n",
    "x_train = train_set.drop('Survived', axis=1)\n",
    "y_train = train_set['Survived'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce029d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora los de validación\n",
    "x_val = val_set.drop('Survived', axis=1)\n",
    "y_val = val_set['Survived'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7fcc06",
   "metadata": {},
   "source": [
    "## 4.- Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6bfc57",
   "metadata": {},
   "source": [
    "#### Antes de entrenar al módelo, hay que preparar los datos, como imputar, normalizar o estandarizar y codificar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a722a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43757b1",
   "metadata": {},
   "source": [
    "##### Los NaN son los valores nulos que hay que eliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72db98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_nulls = x_train.columns[x_train.isnull().any()]\n",
    "print(columns_with_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1aa670",
   "metadata": {},
   "source": [
    "#### Estas son las columnas con valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00011d74",
   "metadata": {},
   "source": [
    "### 4.1.- Imputar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785cf4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para imputar los datos importamos simpleimputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# seleccionamos las columnas numericas\n",
    "numeric_columns = x_train.select_dtypes(include=['number']).columns\n",
    "\n",
    "# seleccionamos las categorias\n",
    "cat_columns = x_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Imputamos valores numéricos con la mediana\n",
    "numeric_imputer = SimpleImputer(strategy='median')# instanciamos ese imputador numerico\n",
    "x_train[numeric_columns] = numeric_imputer.fit_transform(x_train[numeric_columns])\n",
    "\n",
    "# Imputamos las categorias con el valor mas frecuente\n",
    "imputer_categorical = SimpleImputer(strategy='most_frequent')# instanciamos ese imputador categorico\n",
    "x_train[cat_columns] = imputer_categorical.fit_transform(x_train[cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f68021",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a4868",
   "metadata": {},
   "source": [
    "#### Los valores nulos se han eliminado, en cambio esta la media y la categoria mas frecuente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e84715e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_with_nulls = x_train.columns[x_train.isnull().any()]\n",
    "print(columns_with_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4562a6",
   "metadata": {},
   "source": [
    "### 4.2.- Normalizar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482f1333",
   "metadata": {},
   "source": [
    "#### Ahora vamos a normalizar los datos, es decir, vamos a hacer que los valores no tengan mucha diferencia entre si, sino que tengan una escala entre 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7c4fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lo haremos con minmaxscaler\n",
    "\n",
    "# Creamos un objeto MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Seleccionamos solo las columnas numéricas para la normalización\n",
    "numeric_cols = x_train.select_dtypes(include='number').columns\n",
    "\n",
    "# Normalizar las columnas numéricas\n",
    "x_train[numeric_cols] = scaler.fit_transform(x_train[numeric_cols])\n",
    "\n",
    "# Ahora, el df contiene las columnas numéricas normalizadas\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d748dfe5",
   "metadata": {},
   "source": [
    "### 4.3.- Codificar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d1769",
   "metadata": {},
   "source": [
    "#### El ultimo paso seria codificarlo, es decir, convertir las categorias (letras), en números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3b577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas categóricas\n",
    "cat_columns1 = x_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Aplicar One-Hot Encoding al conjunto de entrenamiento\n",
    "x_train = pd.get_dummies(x_train, columns=cat_columns1, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcc1a63",
   "metadata": {},
   "source": [
    "#### ok, x_train ya esta, ahora hay que hacer lo mismo con x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f42857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed537cf",
   "metadata": {},
   "source": [
    "#### Lo se, es un coñaso empezar de nuevo, pues por eso estan los pipelines que lo aprenderemos en otro momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77bfbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para imputar los datos importamos simpleimputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# seleccionamos las columnas numericas\n",
    "numeric_columns = x_val.select_dtypes(include=['number']).columns\n",
    "\n",
    "# seleccionamos las categorias\n",
    "cat_columns = x_val.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Imputamos valores numéricos con la mediana\n",
    "numeric_imputer = SimpleImputer(strategy='median')# instanciamos ese imputador numerico\n",
    "x_val[numeric_columns] = numeric_imputer.fit_transform(x_val[numeric_columns])\n",
    "\n",
    "# Imputamos las categorias con el valor mas frecuente\n",
    "imputer_categorical = SimpleImputer(strategy='most_frequent')# instanciamos ese imputador categorico\n",
    "x_val[cat_columns] = imputer_categorical.fit_transform(x_val[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo haremos con minmaxscaler\n",
    "\n",
    "# Creamos un objeto MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Seleccionamos solo las columnas numéricas para la normalización\n",
    "numeric_cols = x_val.select_dtypes(include='number').columns\n",
    "\n",
    "# Normalizar las columnas numéricas\n",
    "x_val[numeric_cols] = scaler.fit_transform(x_val[numeric_cols])\n",
    "\n",
    "# Ahora, el df contiene las columnas numéricas normalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05bd4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas categóricas\n",
    "cat_columns1 = x_val.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Aplicar One-Hot Encoding al conjunto de entrenamiento\n",
    "x_val = pd.get_dummies(x_val, columns=cat_columns1, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba112e55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced10c32",
   "metadata": {},
   "source": [
    "## 5.- Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6246198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a592270",
   "metadata": {},
   "source": [
    "##### Ya tenemos el modelo 🎉\n",
    "##### Ahora solo nos toca predecir nuevos valores y ver quetal se comporta este modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d869292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predic = model.predict(x_val)\n",
    "\n",
    "# Estas son las 5 primeras predicciones de mi modelo para los datos x_val\n",
    "y_val_predic[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c750945f",
   "metadata": {},
   "source": [
    "## 6.- Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b975a5dc",
   "metadata": {},
   "source": [
    "###  Matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d97312e",
   "metadata": {},
   "source": [
    "##### Aqui se ve que 46 ejemplos han dado 0 (no sobrevivio) asertados y 8 no\n",
    "##### Y que 29 ha dado 1 (sobrevivio) asertados y 1 ha dado 29 (no sobrevivio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab96eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "cm = confusion_matrix(y_val, y_val_predic, labels=model.classes_)\n",
    "\n",
    "# Crear una visualización de la matriz de confusión\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "\n",
    "# Mostrar la visualización\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd3914",
   "metadata": {},
   "source": [
    "#### Metricas derivadas de la matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c76f7f0",
   "metadata": {},
   "source": [
    "### Precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd654dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print('Precisión:', precision_score(y_val, y_val_predic, pos_label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a98b06",
   "metadata": {},
   "source": [
    "#### aqui vemos que el 0,7% ha acertado los 0 (no sobrevivio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5199ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print('Precisión:', precision_score(y_val, y_val_predic, pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b3a7f",
   "metadata": {},
   "source": [
    "##### Y un 86% ha acertado con el 1 (sobrevivio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe329e",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd64bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print('Recall:', recall_score(y_val, y_val_predic, pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407a3a37",
   "metadata": {},
   "source": [
    "### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f2e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('f1_score: ', f1_score(y_val, y_val_predic, pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e96ee9b",
   "metadata": {},
   "source": [
    "### Curva de ROC y PR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd696237",
   "metadata": {},
   "source": [
    "#### Curva de ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_val, y_val_predic)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='example estimator')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
