{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ff970e",
   "metadata": {},
   "source": [
    "#### Primero importamos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3548785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para convertirlo en un df\n",
    "import pandas as pd\n",
    "# Para c谩lculos numericos\n",
    "import numpy as np\n",
    "# Para graficar\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Para normalizar los datos\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb16efe",
   "metadata": {},
   "source": [
    "## ***1.- Recopilaci贸n de Datos***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf656ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/titanik_train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4da90af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# por si acaso creamos una copia del df\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b5af0e",
   "metadata": {},
   "source": [
    "## **2.- Exploraci贸n y An谩lisis de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee5eab95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d92a75d",
   "metadata": {},
   "source": [
    "##### Seg煤n donde saque este dataset, survived representa con un 1 si sobrevivieron y 0 si no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f9bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vemos algunas metricas como la mediana, minimo, maximo etc..\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43022b41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22694007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c93ca28",
   "metadata": {},
   "source": [
    "#### Vamos a visualizar un poco nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a70d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Sex', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182fe70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='Embarked', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef988c",
   "metadata": {},
   "source": [
    "#### Nos conviene estratificar tambien la columna embarked, ya que esta un poco desigual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d4000",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Ticket', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b53ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='Cabin', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eda55e",
   "metadata": {},
   "source": [
    "#### Como vemos hay un monton de caracteristicas en el ticket y en cabin, nos convendria eliminarlos para hacer nuesto modelo mas sencillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5cb5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos ticket\n",
    "columna_a_eliminar = 'Ticket'\n",
    "df = df.drop(columna_a_eliminar, axis=1)\n",
    "\n",
    "# Eliminamos Cabin\n",
    "columna_a_eliminar = 'Cabin'\n",
    "df = df.drop(columna_a_eliminar, axis=1)\n",
    "\n",
    "# de paso eliminamos la columna name tambien ya que no parece muy relevante\n",
    "columna_a_eliminar = 'Name'\n",
    "df = df.drop(columna_a_eliminar, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8cbe57",
   "metadata": {},
   "source": [
    "## 3.- Divisi贸n de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e872e120",
   "metadata": {},
   "source": [
    "#### Hay que dividir los datos en entrenamiento, evaluaci贸n y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616237e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos train_test_split para dividir los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, val_set = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'la longitud de train_set es de: {len(train_set)}')\n",
    "print(f'la longitud de val_set es de: {len(val_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b297b2ed",
   "metadata": {},
   "source": [
    "#### Ahora separamos las etiquetas (salidas 'y'), de las caracteristicas (entradas 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos el de entrenamiento \n",
    "x_train = train_set.drop('Survived', axis=1)\n",
    "y_train = train_set['Survived'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce029d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora los de validaci贸n\n",
    "x_val = val_set.drop('Survived', axis=1)\n",
    "y_val = val_set['Survived'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7fcc06",
   "metadata": {},
   "source": [
    "## 4.- Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6bfc57",
   "metadata": {},
   "source": [
    "#### Antes de entrenar al m贸delo, hay que preparar los datos, como imputar, normalizar o estandarizar y codificar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a722a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43757b1",
   "metadata": {},
   "source": [
    "##### Los NaN son los valores nulos que hay que eliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72db98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_nulls = x_train.columns[x_train.isnull().any()]\n",
    "print(columns_with_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1aa670",
   "metadata": {},
   "source": [
    "#### Estas son las columnas con valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00011d74",
   "metadata": {},
   "source": [
    "### 4.1.- Imputar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785cf4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para imputar los datos importamos simpleimputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# seleccionamos las columnas numericas\n",
    "numeric_columns = x_train.select_dtypes(include=['number']).columns\n",
    "\n",
    "# seleccionamos las categorias\n",
    "cat_columns = x_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Imputamos valores num茅ricos con la mediana\n",
    "numeric_imputer = SimpleImputer(strategy='median')# instanciamos ese imputador numerico\n",
    "x_train[numeric_columns] = numeric_imputer.fit_transform(x_train[numeric_columns])\n",
    "\n",
    "# Imputamos las categorias con el valor mas frecuente\n",
    "imputer_categorical = SimpleImputer(strategy='most_frequent')# instanciamos ese imputador categorico\n",
    "x_train[cat_columns] = imputer_categorical.fit_transform(x_train[cat_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f68021",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a4868",
   "metadata": {},
   "source": [
    "#### Los valores nulos se han eliminado, en cambio esta la media y la categoria mas frecuente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e84715e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_with_nulls = x_train.columns[x_train.isnull().any()]\n",
    "print(columns_with_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14442796",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4562a6",
   "metadata": {},
   "source": [
    "### 4.2.- Normalizar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482f1333",
   "metadata": {},
   "source": [
    "#### Ahora vamos a normalizar los datos, es decir, vamos a hacer que los valores no tengan mucha diferencia entre si, sino que tengan una escala entre 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7c4fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lo haremos con minmaxscaler\n",
    "\n",
    "# Creamos un objeto MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Seleccionamos solo las columnas num茅ricas para la normalizaci贸n\n",
    "numeric_cols = x_train.select_dtypes(include='number').columns\n",
    "\n",
    "# Normalizar las columnas num茅ricas\n",
    "x_train[numeric_cols] = scaler.fit_transform(x_train[numeric_cols])\n",
    "\n",
    "# Ahora, el df contiene las columnas num茅ricas normalizadas\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d748dfe5",
   "metadata": {},
   "source": [
    "### 4.3.- Codificar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d1769",
   "metadata": {},
   "source": [
    "#### El ultimo paso seria codificarlo, es decir, convertir las categorias (letras), en n煤meros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3b577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas categ贸ricas\n",
    "cat_columns1 = x_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Aplicar One-Hot Encoding al conjunto de entrenamiento\n",
    "x_train = pd.get_dummies(x_train, columns=cat_columns1, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f4e7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de6fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcc1a63",
   "metadata": {},
   "source": [
    "#### ok, x_train ya esta, ahora hay que hacer lo mismo con x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f42857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed537cf",
   "metadata": {},
   "source": [
    "#### Lo se, es un co帽aso empezar de nuevo, pues por eso estan los pipelines que lo aprenderemos en otro momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77bfbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para imputar los datos importamos simpleimputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# seleccionamos las columnas numericas\n",
    "numeric_columns = x_val.select_dtypes(include=['number']).columns\n",
    "\n",
    "# seleccionamos las categorias\n",
    "cat_columns = x_val.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Imputamos valores num茅ricos con la mediana\n",
    "numeric_imputer = SimpleImputer(strategy='median')# instanciamos ese imputador numerico\n",
    "x_val[numeric_columns] = numeric_imputer.fit_transform(x_val[numeric_columns])\n",
    "\n",
    "# Imputamos las categorias con el valor mas frecuente\n",
    "imputer_categorical = SimpleImputer(strategy='most_frequent')# instanciamos ese imputador categorico\n",
    "x_val[cat_columns] = imputer_categorical.fit_transform(x_val[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo haremos con minmaxscaler\n",
    "\n",
    "# Creamos un objeto MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Seleccionamos solo las columnas num茅ricas para la normalizaci贸n\n",
    "numeric_cols = x_val.select_dtypes(include='number').columns\n",
    "\n",
    "# Normalizar las columnas num茅ricas\n",
    "x_val[numeric_cols] = scaler.fit_transform(x_val[numeric_cols])\n",
    "\n",
    "# Ahora, el df contiene las columnas num茅ricas normalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05bd4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas categ贸ricas\n",
    "cat_columns1 = x_val.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Aplicar One-Hot Encoding al conjunto de entrenamiento\n",
    "x_val = pd.get_dummies(x_val, columns=cat_columns1, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba112e55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6233c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_train.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced10c32",
   "metadata": {},
   "source": [
    "## 5.- Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6246198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a592270",
   "metadata": {},
   "source": [
    "##### Ya tenemos el modelo \n",
    "##### Ahora solo nos toca predecir nuevos valores y ver quetal se comporta este modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d869292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predic = model.predict(x_val)\n",
    "\n",
    "# Estas son las 5 primeras predicciones de mi modelo para los datos x_val\n",
    "y_val_predic[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c750945f",
   "metadata": {},
   "source": [
    "## 6.- Evaluaci贸n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b975a5dc",
   "metadata": {},
   "source": [
    "###  Matriz de confusi贸n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d97312e",
   "metadata": {},
   "source": [
    "##### Aqui se ve que 46 ejemplos han dado 0 (no sobrevivio) asertados y 8 no\n",
    "##### Y que 29 ha dado 1 (sobrevivio) asertados y 1 ha dado 29 (no sobrevivio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab96eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Calcular la matriz de confusi贸n\n",
    "cm = confusion_matrix(y_val, y_val_predic, labels=model.classes_)\n",
    "\n",
    "# Crear una visualizaci贸n de la matriz de confusi贸n\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "\n",
    "# Mostrar la visualizaci贸n\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd3914",
   "metadata": {},
   "source": [
    "#### Metricas derivadas de la matriz de confusi贸n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c76f7f0",
   "metadata": {},
   "source": [
    "### Precisi贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd654dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print('Precisi贸n:', precision_score(y_val, y_val_predic, pos_label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a98b06",
   "metadata": {},
   "source": [
    "#### aqui vemos que el 0,7% ha acertado los 0 (no sobrevivio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5199ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print('Precisi贸n:', precision_score(y_val, y_val_predic, pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b3a7f",
   "metadata": {},
   "source": [
    "##### Y un 86% ha acertado con el 1 (sobrevivio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe329e",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd64bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print('Recall:', recall_score(y_val, y_val_predic, pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407a3a37",
   "metadata": {},
   "source": [
    "### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f2e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('f1_score: ', f1_score(y_val, y_val_predic, pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e96ee9b",
   "metadata": {},
   "source": [
    "### Curva de ROC y PR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd696237",
   "metadata": {},
   "source": [
    "#### Curva de ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_val, y_val_predic)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='example estimator')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
